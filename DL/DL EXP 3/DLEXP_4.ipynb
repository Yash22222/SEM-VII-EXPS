{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ***Implement a backpropagation algorithm to train a DNN with at least 2 hidden layers.***"
      ],
      "metadata": {
        "id": "qmJIc3Nq4X2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Yash Ashok Shirsath BE AI & DS 65***"
      ],
      "metadata": {
        "id": "W0bEM5WF4zzk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r4I1ALOc00gN"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def mean_squared_error_derivative(y_true, y_pred):\n",
        "    return y_pred - y_true"
      ],
      "metadata": {
        "id": "cptVylcB5Kbl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNeuralNetwork:\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
        "        self.weights1 = np.random.randn(input_size, hidden1_size)\n",
        "        self.biases1 = np.zeros((1, hidden1_size))\n",
        "\n",
        "        self.weights2 = np.random.randn(hidden1_size, hidden2_size)\n",
        "        self.biases2 = np.zeros((1, hidden2_size))\n",
        "\n",
        "        self.weights3 = np.random.randn(hidden2_size, output_size)\n",
        "        self.biases3 = np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = np.dot(X, self.weights1) + self.biases1\n",
        "        self.a1 = sigmoid(self.z1)\n",
        "\n",
        "        self.z2 = np.dot(self.a1, self.weights2) + self.biases2\n",
        "        self.a2 = sigmoid(self.z2)\n",
        "\n",
        "        self.z3 = np.dot(self.a2, self.weights3) + self.biases3\n",
        "        self.a3 = sigmoid(self.z3)\n",
        "\n",
        "        return self.a3\n",
        "\n",
        "    def backward(self, X, y, learning_rate=0.01):\n",
        "        output_error = mean_squared_error_derivative(y, self.a3)\n",
        "        output_delta = output_error * sigmoid_derivative(self.z3)\n",
        "\n",
        "        hidden2_error = np.dot(output_delta, self.weights3.T)\n",
        "        hidden2_delta = hidden2_error * sigmoid_derivative(self.z2)\n",
        "\n",
        "        hidden1_error = np.dot(hidden2_delta, self.weights2.T)\n",
        "        hidden1_delta = hidden1_error * sigmoid_derivative(self.z1)\n",
        "\n",
        "        self.weights3 -= learning_rate * np.dot(self.a2.T, output_delta)\n",
        "        self.biases3 -= learning_rate * np.sum(output_delta, axis=0, keepdims=True)\n",
        "\n",
        "        self.weights2 -= learning_rate * np.dot(self.a1.T, hidden2_delta)\n",
        "        self.biases2 -= learning_rate * np.sum(hidden2_delta, axis=0, keepdims=True)\n",
        "\n",
        "        self.weights1 -= learning_rate * np.dot(X.T, hidden1_delta)\n",
        "        self.biases1 -= learning_rate * np.sum(hidden1_delta, axis=0, keepdims=True)\n",
        "\n",
        "    def train(self, X, y, epochs=1000, learning_rate=0.01):\n",
        "        for epoch in range(epochs):\n",
        "            predictions = self.forward(X)\n",
        "            loss = mean_squared_error(y, predictions)\n",
        "            self.backward(X, y, learning_rate)\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')"
      ],
      "metadata": {
        "id": "7f7Zs_ud5T8J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # (X: 4 samples, 3 features; y: 4 samples, 1 output)\n",
        "    X = np.array([[0, 0, 1],\n",
        "                  [0, 1, 1],\n",
        "                  [1, 0, 1],\n",
        "                  [1, 1, 1]])\n",
        "\n",
        "    y = np.array([[0],\n",
        "                  [1],\n",
        "                  [1],\n",
        "                  [0]])\n",
        "\n",
        "    nn = DeepNeuralNetwork(input_size=3, hidden1_size=4, hidden2_size=4, output_size=1)\n",
        "    nn.train(X, y, epochs=1000, learning_rate=0.01)\n",
        "\n",
        "    predictions = nn.forward(X)\n",
        "    print(\"Predictions:\\n\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Wg2uEjG55Z1b",
        "outputId": "e8c30618-1dba-427f-9ff1-6deb99c6d377"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2560802230469403\n",
            "Epoch 100, Loss: 0.2525861776375419\n",
            "Epoch 200, Loss: 0.25111223828442747\n",
            "Epoch 300, Loss: 0.25050200449669635\n",
            "Epoch 400, Loss: 0.2502507739437637\n",
            "Epoch 500, Loss: 0.2501471639699176\n",
            "Epoch 600, Loss: 0.2501040229234156\n",
            "Epoch 700, Loss: 0.2500856222735877\n",
            "Epoch 800, Loss: 0.2500773416056735\n",
            "Epoch 900, Loss: 0.25007320063279187\n",
            "Predictions:\n",
            " [[0.49882959]\n",
            " [0.49970694]\n",
            " [0.49858157]\n",
            " [0.4997384 ]]\n"
          ]
        }
      ]
    }
  ]
}