{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ***NLP EXPERIMENT NO - 7***"
      ],
      "metadata": {
        "id": "L6zpZoXBf98u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***AIM - Perform Chunking by Analyzing the Importance of Selecting Proper Features for Training a Model & Size of Training***"
      ],
      "metadata": {
        "id": "6z_NcMm4gWFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "n_rows = 100\n",
        "n_cols = 10\n",
        "\n",
        "df = pd.DataFrame(np.random.rand(n_rows, n_cols), columns=[f'Feature_{i}' for i in range(n_cols)])\n",
        "df['Target'] = np.random.randint(0, 2, n_rows)\n",
        "\n",
        "feature_importances = mutual_info_classif(df.drop('Target', axis=1), df['Target'])\n",
        "feature_importances = sorted(zip(df.columns[:-1], feature_importances), key=lambda x: x[1], reverse=True)\n",
        "k = 5\n",
        "top_features = [feature[0] for feature in feature_importances[:k]]\n",
        "\n",
        "chunks = []\n",
        "for i in range(0, len(df), k):\n",
        "    chunk = df[top_features + ['Target']].iloc[i:i+k]\n",
        "    chunks.append(chunk)\n",
        "\n",
        "chunk_sizes = [len(chunk) for chunk in chunks]\n",
        "print(\"Chunk sizes:\", chunk_sizes)\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(chunk.drop('Target', axis=1), chunk['Target'], test_size=0.2, random_state=42)\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Chunk {i+1}: Accuracy = {accuracy:.3f}\")"
      ],
      "metadata": {
        "id": "m51Ku97PSbtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2b151b45-3a31-441c-a94a-a85cba5fb4d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk sizes: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
            "Chunk 1: Accuracy = 0.000\n",
            "Chunk 2: Accuracy = 1.000\n",
            "Chunk 3: Accuracy = 1.000\n",
            "Chunk 4: Accuracy = 1.000\n",
            "Chunk 5: Accuracy = 0.000\n",
            "Chunk 6: Accuracy = 0.000\n",
            "Chunk 7: Accuracy = 0.000\n",
            "Chunk 8: Accuracy = 0.000\n",
            "Chunk 9: Accuracy = 0.000\n",
            "Chunk 10: Accuracy = 1.000\n",
            "Chunk 11: Accuracy = 1.000\n",
            "Chunk 12: Accuracy = 0.000\n",
            "Chunk 13: Accuracy = 0.000\n",
            "Chunk 14: Accuracy = 0.000\n",
            "Chunk 15: Accuracy = 0.000\n",
            "Chunk 16: Accuracy = 1.000\n",
            "Chunk 17: Accuracy = 1.000\n",
            "Chunk 18: Accuracy = 0.000\n",
            "Chunk 19: Accuracy = 1.000\n",
            "Chunk 20: Accuracy = 1.000\n"
          ]
        }
      ]
    }
  ]
}