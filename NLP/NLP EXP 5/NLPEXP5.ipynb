{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##***Aim - Implement N-Gram model for the Given Text Input***"
      ],
      "metadata": {
        "id": "Pfi6CIypUnRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Yash Ashok Shirsath BE AI & DS 65***"
      ],
      "metadata": {
        "id": "l-zevlMcU2go"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "8kYA23c-T5eF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "    \"\"\"\n",
        "    Tokenize the input text into a list of words.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of words.\n",
        "    \"\"\"\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.split()"
      ],
      "metadata": {
        "id": "PiwHYnQlZC10"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngram_model(sentences, n):\n",
        "    \"\"\"\n",
        "    Build an N-Gram model from the input sentences.\n",
        "\n",
        "    Args:\n",
        "        sentences (list): A list of sentences.\n",
        "        n (int): The order of the N-Gram model.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary representing the N-Gram model.\n",
        "    \"\"\"\n",
        "    model = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenize_text(sentence)\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            context = tuple(tokens[i:i + n - 1])\n",
        "            next_word = tokens[i + n - 1]\n",
        "            model[context][next_word] += 1\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3QM1QgHiYCig"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, context):\n",
        "    \"\"\"\n",
        "    Predict the next word given the context.\n",
        "\n",
        "    Args:\n",
        "        model (dict): The N-Gram model.\n",
        "        context (tuple): The context words.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted next word.\n",
        "    \"\"\"\n",
        "    if context not in model:\n",
        "        return \"unknown\"\n",
        "\n",
        "    next_words = model[context]\n",
        "    return max(next_words, key=next_words.get)"
      ],
      "metadata": {
        "id": "T9uxkz4hamAN"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Indian Railways is a statutory body under the ownership of the Ministry of Railways of the Government of India.\",\n",
        "    \"It operates India's national railway system. The railways play a crucial role in the transportation infrastructure of the country.\",\n",
        "    \"The Indian Railways network is one of the largest in the world and serves millions of passengers every day.\"\n",
        "]\n",
        "n = 2\n",
        "\n",
        "model = build_ngram_model(sentences, n)\n",
        "\n",
        "contexts = [\n",
        "    (\"Indian\",),\n",
        "    (\"It\",),\n",
        "    (\"The\", \"Indian\"),\n",
        "    (\"railways\", \"play\"),\n",
        "    (\"of\", \"the\")\n",
        "]\n",
        "\n",
        "for context in contexts:\n",
        "    next_word = predict_next_word(model, context)\n",
        "    print(f\"Context: {context}, Predicted next word: {next_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYvm4W8BZLEM",
        "outputId": "974e90eb-75fc-4813-92fe-d11ea3b86c7e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ('Indian',), Predicted next word: Railways\n",
            "Context: ('It',), Predicted next word: operates\n",
            "Context: ('The', 'Indian'), Predicted next word: unknown\n",
            "Context: ('railways', 'play'), Predicted next word: unknown\n",
            "Context: ('of', 'the'), Predicted next word: unknown\n"
          ]
        }
      ]
    }
  ]
}